---
title: 算法导论(3) 哈希
published: 2025-09-17
description: ''
image: ''
tags: []
category: ''
draft: false 
lang: ''
---

## 字典(Dictionary)
一种抽象数据类型. 其维护某个集合, 集合中的每个元素item都含有键key.
拥有如下操作:
1. 插入: insert(item)
2. 删除: delete(item)
3. 查找: search(key)

python的内置类**字典**实现了上述功能, 每个元素都为一个键-值对.

我们知道, 平衡BST能在$O(log n)$内解决如上问题.

**能不能更快?**

## 直接寻址表(Direct Access Table)
最简单的想法就是建立一个数组, 由于数组的(指定索引)随机访问的效率是$O(1)$, 可以再设置一个状态保存空元素. 于是:
1. insert(key, value): arr[key] = value
2. delete(key, value): arr[key] = EMPTY
3. search(key): return arr[key]

我们就完成了上述目标. 然而聪明的同学可能已经发现, 我们这个实现有很多问题:
1. 最主要的问题是key只能是非负整数, 而我们往往需要以字符串或者其他类型作为key.
2. 假如key的分布比较稀疏(e.g. key[0] = 1, key[1] = 100000000000), 那么即使我们只需要存两个元素, 也得开100000000000以上的空间!

### 问题1的解决: prehash
将任意类型的键，确定性地转换成一个整数. 
我们暂时不讲这个转换方法, 后面会讲到. 目前只需要知道是可以做到把任意类型的键映射到一个整数的就行.
python内置了这个方法, 即$hash()$函数. 对于自定义对象可以使用__hash__方法.

### 问题2的解决: hashing
我们现在有了一个(可能非常大的)整数键。我们需要将这个巨大的整数域(称为全域U)，映射到一个大小合理的、可以作为数组索引的小范围 [0, 1, ..., m-1] 中。m 就是我们哈希表(数组)的大小.
这个映射叫做哈希函数(hash function). 这里同样不讲哈希函数的具体实现.

通过预哈希和哈希函数可以将n个不同元素映射到m个不同的桶(或槽位, slot)中. 在理想情况下m = n, 并且每个桶恰好储存一个元素. 这样既不会浪费空间, 也能精确查找.

然而我们发现, 这是难以做到的.

## 哈希碰撞/哈希冲突
我们将一个巨大的整数域映射到了一个小范围里, 由于所有可能的键的数量远大于m, 根据抽屉原理, 必然会有多个不同的键$k_1, k_2, ... k_s$被映射到同一个桶中. 假如说我们的元素恰好被prehash到了$k_1, k_2, ... k_s$的某些键当中, 就必然出现同一个桶里储存了不同的元素. 这就叫做**哈希碰撞**(或哈希冲突, Collisions).

如何处理冲突，是整个哈希技术的核心和灵魂. 我们课程里会介绍两种主流的冲突解决方式. 这里介绍**拉链法**, 后续课程中会介绍**开放寻址法**.

### 拉链法(Chaining)
让哈希表的每个桶不止储存一个元素, 而是储存一个链表:
1. insert(key, value): arr[key].append(value)
2. delete(key, value): arr[key].remove(value)
3. search(key): return arr[key].find(value)

好结局: 所有数据均匀分配到各个桶中, 我们只需要花费常数复杂度的代价即可解决哈希冲突.

坏结局: 我们的运气极差, 所有 n 个键都被哈希到了同一个桶中. 这时, 哈希表退化成了一个长链表, 所有操作的时间复杂度都变成了O(n), 我们的 O(1) 梦想破灭了. <del>(建议买彩票)</del>

为了(在大多数情况下)避免坏结局, 我们必须让键均匀地分配到各个桶中. 让每个链表都尽可能短.

### 简单均匀哈希假设(Simple Uniform Hashing Assumption)
一个理想化的哈希函数, 所有数据分配到各个桶中的概率均等(为1/m)并且互相独立. 

这时, 每个桶中的链表长度期望值为n / m, 称为**负载因子**(Load Factor), 记作
$$
\alpha = \frac{n}{m}
$$
.

简单均匀哈希假设下, 所有操作的期望平均时间复杂度为$\Theta (1 + \alpha)$. 那么我们如果能够把负载因子保持在一个常数, 这个复杂度就是$\Theta(1)$.

由于$\alpha = \frac{n}{m}$, 也就是说, 我们需要让$n$与$m$成正比.

这是一个理想化的假设, 我们的目标是设计出尽可能接近这个假设的哈希函数.

### 除法哈希
除法哈希, 或者叫模哈希. $hashing(k) = k \% m$.
优点在于简单快速. 关键在于m的选择, 为了避开数据可能的分布规律, m不应被选择为2的整数次幂或10的整数次幂.

一般来说, 我们选择m为一个远离2的幂次的质数.

### 乘法哈希
没有完全看懂, 这里把gemini的回答复制过来.


:::note
此内容待完善, 以下为gemini的回答.
:::

:::tip[gemini对乘法哈希的解释]
这是一个非常值得深入探讨的问题。乘法哈希法在初看时确实比除法哈希法要“绕”一些，但一旦理解了它背后的思想，你就会发现它在计算机中的实现是何其地优雅和高效。

让我们循序渐进，从直观思想到具体实现，把这个方法彻底搞明白。

#### 第一部分：核心思想 —— 制造“混乱”与提取“精华”

所有哈希函数的共同目标都是：**将输入的键（key）尽可能均匀地、看似随机地“打乱”并散布到哈希表的槽位中**。

*   **除法哈希法 (`k mod m`) 的问题**: 它的“打乱”效果完全依赖于`m`。如果`k`和`m`有共同的因子，或者`k`的分布有某种规律性，`k mod m`的结果就可能不均匀。比如，如果`m=100`，而你的键都是10的倍数，那么所有键只会映射到10个槽位，90%的空间都被浪费了。

*   **乘法哈希法的思想**: 它采用了一种更主动、更彻底的“打乱”方式。
    1.  **制造混乱 (Scrambling)**: 它先用一个精心挑选的“魔数”（乘数`a`）去乘以键`k`。乘法这个操作，特别是当数字很大并发生溢出时，具有非常好的“雪崩效应”——输入键`k`的微小变化，都会导致乘积结果的巨大变化，所有比特位都会被充分地搅乱。
    2.  **提取精华 (Extracting)**: 从这个被搅乱的、非常大的乘积结果中，我们不取低位（像`mod`那样），而是**提取中间或高位的某一部分比特**作为最终的哈希值。为什么？因为乘积的中间部分比特，是受输入键`k`的**所有比特位**共同影响的结果，因此它包含了最“混乱”、分布最均匀的信息。


#### 第二部分：从数学理想到计算机实现

讲义上其实提到了两种形式的乘法哈希，我们先从更容易理解的数学形式开始。

##### 1. 理论数学形式 (小数法)

`h(k) = floor(m * (k * A mod 1))`

这里的 `A` 是一个 `0 < A < 1` 之间的常数（比如黄金分割比 `(sqrt(5)-1)/2 ≈ 0.618`）。

*   `k * A`: 将键`k`乘以一个小数。
*   `k * A mod 1`: 这句是关键，它的意思是**只取 `k * A` 的小数部分**。例如，`3.14159 mod 1 = 0.14159`。这个小数部分对`k`的变化非常敏感。
*   `m * (...)`: 将这个`[0, 1)`之间的小数，放大`m`倍，使其范围扩展到`[0, m)`。
*   `floor(...)`: 取整，得到一个`[0, m-1]`之间的整数索引。

**直观理解**: 想象一个周长为1的圆盘。每次乘以`A`，就像在圆盘上旋转一个固定的角度。`k*A`就是旋转`k`次。`k*A mod 1`就是旋转`k`次后的最终位置。这个位置看起来是相当随机的。然后我们把圆盘分成`m`个扇区，看它落在了哪个扇区，这就是哈希值。

这个方法很优美，但在计算机里用浮点数进行这种计算，既慢又不精确。于是，计算机科学家们发明了等价的、只用整数和位运算的实现方法。

##### 2. 计算机实现形式 (整数与位运算法)

这就是讲义中的公式：`h(k) = [(a * k) mod 2^w] >> (w - r)`

让我们来逐一拆解这个公式里的每一个部分，这正是它的精髓所在。

*   **`w` (word size)**: 计算机的字长，比如32位或64位。这代表了我们处理整数的“世界大小”。
*   **`m` (table size)**: 哈希表的大小。**乘法哈希法的一个巨大优势是，`m`可以方便地设置为2的幂**，即 `m = 2^r`。
*   **`r`**: `m = 2^r`中的指数。它代表了哈希值需要多少个比特位。例如，如果哈希表大小`m=1024`，那么`r=10`，因为 `2^10 = 1024`。
*   **`k`**: 我们的输入键（一个`w`位的整数）。
*   **`a`**: 那个精心挑选的“魔数”（也是一个`w`位的整数）。它通常是一个大的、奇数的、不接近2的幂的数。

**计算步骤：**

1.  **`a * k`**: 将`w`位的`a`和`w`位的`k`相乘。结果会是一个`2w`位的巨大整数。
    `[ ... w bits ... | ... w bits ... ]`

2.  **`(a * k) mod 2^w`**: 这是最巧妙的一步！在`w`位的计算机中，当我们做整数乘法时，如果结果超出了`w`位，计算机会**自动丢弃最高位的`w`个比特，只保留低位的`w`个比特**。这个行为天然地就完成了 `mod 2^w` 的操作！这一步在硬件层面是“免费”的，速度极快。
    `[ ... w bits ... ]` (只保留了乘积的低`w`位)

3.  **`>> (w - r)`**: `>>`是**按位右移**操作。这一步就是我们前面说的“提取精华”。我们将上一步得到的`w`位结果，向右移动 `(w-r)` 位。
    *   **效果**: 这会丢弃掉右边（低位）的 `w-r` 个比特。
    *   **剩下什么**: 原来左边（高位）的 `r` 个比特，现在移动到了最右边，成为了最终的结果。

**为什么这个结果就是好的哈希值？**
因为 `(a*k) mod 2^w` 这一步得到的`w`位结果，它的高位部分（左边的`r`位），是受原始键`k`的所有位和乘数`a`的所有位共同剧烈影响而产生的，分布非常均匀。我们通过右移操作，精准地把这部分“精华”提取了出来，作为哈希表的索引。


#### 第三部分：一个具体的例子

让我们用小一点的数字来模拟这个过程，看得更清楚。

假设我们在一台**8位**的计算机上 (`w=8`)。
我们的哈希表大小是 **16** (`m=16`)，所以 `r=4` (因为 `2^4 = 16`)。
我们选择一个魔数 `a = 101` (二进制 `01100101`)。
我们要哈希的键是 `k = 42` (二进制 `00101010`)。

1.  **`a * k`**:
    `101 * 42 = 4242`
    `4242`的二进制表示是 `00010000 10010010` (这是一个16位的数)。

2.  **`(a * k) mod 2^w`**:
    我们取`4242`对 `2^8 = 256` 取模。
    `4242 mod 256 = 130`
    在计算机中，这相当于直接取16位结果`00010000 10010010`的低8位，即 `10010010`。
    `10010010` (二进制) = `130` (十进制)。

3.  **`>> (w - r)`**:
    现在我们要对上一步的结果 `130` (即`10010010`) 进行位移。
    位移的位数是 `w - r = 8 - 4 = 4`。
    所以我们执行 `130 >> 4`。
    `10010010 >> 4`
    把右边的4位 (`0010`) 丢弃，整个数字向右移动4位，左边补0。
    结果是 `00001001`。

4.  **最终结果**:
    `00001001` (二进制) = `9` (十进制)。
    所以，`h(42) = 9`。键`42`被映射到了哈希表的第9号槽位。


#### 总结：为什么乘法哈希法这么好？

1.  **速度极快**: 它只用了CPU中最高效的指令：整数乘法和位移。这远比又慢又不方便的整数除法要快得多。
2.  **对`m`的选择友好**: `m`可以是任何2的幂。这在计算机中非常方便，因为数组大小设为2的幂，地址计算会更简单高效。而除法哈希法为了避免冲突，要求`m`最好是质数，寻找和使用质数都更麻烦。
3.  **打乱效果好**: 乘法操作能很好地将输入键的规律性打乱，生成分布均匀的哈希值，从而有效避免冲突。

希望这个从思想到实现再到具体例子的分步解释，能让你彻底明白乘法哈希法的精妙之处！明白乘法哈希法的精妙之处！
:::